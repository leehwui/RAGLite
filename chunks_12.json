[
  "import ollama\nimport numpy as np\n\n# Configuration for Ollama connection\nOLLAMA_HOST = \"http://localhost:11434\"  # Change this if your Ollama is running on a different host/port\nclient = ollama.Client(host=OLLAMA_HOST)\n\n# Configuration f",
  "or output\nPRINT_EMBEDDINGS = False  # Set to True to see the actual embedding vectors (they are long numerical arrays)\n\n# Function to get embedding from Ollama\ndef get_embedding(text, model):\n    response = client.embeddings(model=model",
  ", prompt=text)\n    return np.array(response['embedding'])\n\n# Test cases for different languages\ntest_cases = [\n    {\n        'language': 'English',\n        'query': 'buy apple',\n        'document': \"\"\"\nOur company specializes in supplyi",
  "ng fresh fruits to retailers and wholesalers.\nWe offer a wide range of fruits.\nFor bulk purchases and special orders, please contact our sales team.\nWe ensure high quality and timely delivery for all our products.\n\"\"\"\n    },\n    {\n     ",
  "   'language': 'Chinese',\n        'query': '买香蕉',\n        'document': \"\"\"\n 3 青岛青饮国际贸易有限公司 崂矿大桶水 傅鹏 13589227170 季度结算 4 倩倩水果店 水果 倩 倩 15192592597 现结 要水果单价和账单（免费送货上门） 5 恩丽源餐饮公司（食堂） 茶歇点心 大厨-王恩峰 13698699488 对公月结 经济、实惠、健康、安全\n\"\"\"\n    }\n]\n\n# Lis",
  "t of embedding models to test (assuming they are available in Ollama)\nmodels = ['qwen3-embedding:8b', 'bge-m3:latest', 'shaw/dmeta-embedding-zh:latest']\n\nfor test_case in test_cases:\n    language = test_case['language']\n    query = test",
  "_case['query']\n    document = test_case['document']\n    \n    print(f\"\\n=== Testing in {language} ===\")\n    print(f\"Connecting to Ollama at: {OLLAMA_HOST}\")\n    print(f\"Query: '{query}'\")\n    print(\"Document: {}\".format(document.strip())",
  ")\n    print(f\"Print embeddings: {PRINT_EMBEDDINGS}\")\n    print(\"\\n\" + \"=\"*50)\n    \n    for model in models:\n        try:\n            # Get embeddings\n            doc_embedding = get_embedding(document, model)\n            query_embedding",
  " = get_embedding(query, model)\n\n            # Calculate cosine similarity\n            similarity = np.dot(doc_embedding, query_embedding) / (\n                np.linalg.norm(doc_embedding) * np.linalg.norm(query_embedding)\n            )\n",
  "\n            print(f\"Model: {model}\")\n            print(f\"Similarity: {similarity:.4f}\")\n            if PRINT_EMBEDDINGS:\n                print(f\"Query embedding (first 10 values): {query_embedding[:10]}\")\n                print(f\"Docume",
  "nt embedding (first 10 values): {doc_embedding[:10]}\")\n                print(f\"Embedding dimensions: {len(query_embedding)}\")\n            print(\"-\"*30)\n        except Exception as e:\n            print(f\"Error with model {model}: {e}\")\n ",
  "           print(\"-\"*30)\n\nprint(\"\\nNote: Higher similarity scores indicate better semantic matching.\")\nprint(\"This test measures how well the models bridge the semantic gap between\")\nprint(\"the queries and documents in both English and Chinese.\")"
]